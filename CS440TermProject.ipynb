{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-d4eea66f-f8f3-4864-b5a5-3756b5f11083",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# CS440 Term Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-5083d6c9-5b03-46c8-b045-84301a3a5885",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Data Source: https://finance.yahoo.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-14950b5c-7f87-41e8-bcf7-fb159839f653",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Project Description\n",
    "\n",
    "In today’s modern world, staying updated on technological advancements has become a necessity for businesses to satisfy their customers, achieve desired business goals, and most importantly outsmart the competition. In recent years, the financial sector has seen a rapid acceleration in the use of Artificial Intelligence (AI) and Machine Learning (ML) due to improved software and hardware. This has led to better outcomes for both consumers and businesses. Hedge funds were the primary users of AI and ML in financial services, but in the last few years, the spread of ML applications was seen in banks, insurance firms, and other financial institutions, to name a few. But the most steadfast and steep increase has been seen in the stock markets. AI and ML are shaping the future of stock markets. Using different techniques and deep learning algorithms, it analyzes millions of data points, predicts forecast markets with better accuracy, and as a result, there is a higher probability for higher profits and returns. \n",
    "\n",
    "The prediction of the volatile and unpredictable stock market has been challenging in recent years, since there are so many factors to take into consideration, such as economic factors, interest rate changes, and fiscal policy. While humans remain a large part of the trading, the stock market has become more efficient and accurate because of the recent developments in AI and ML. These techniques have made it easier for beginners to invest in the stock market. AI and ML also use pattern recognition and help gather unbiased information which leads to better predictions for traders and investors. \n",
    "\n",
    "The goal of this project is to train stock market datasets using different AI and ML algorithms such as Neural Networks, k-Nearest Neighbors (kNN), and Logistic Regression and try to find the best predictions. We aim to get results using the above three algorithms and see which ones best predict the outcomes of the stock market. The goal is to see which algorithm more accurately and efficiently predicts the stock market. The benefits of using these algorithms to predict outcomes are that it extracts noise and leaves out as much signal as possible and time complexity is less, hence results are available faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-898ee7a3-0a3d-4810-bfe1-685476258557",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Data Description\n",
    "\n",
    "This dataset includes the historical daily prices and volume information for US stocks and ETFs trading on NASDAQ, NYSE, and NYSE MKT. We do not believe using stock open and close prices and volume will be enough to predict accurately. We will need to use other ‘technical’ data like RSI which represents the relative strength of a stock and other indicators along with the open and close price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-4430d918-c1cc-454a-a744-818807a337d3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8451,
    "execution_start": 1636849659259,
    "source_hash": "8aebdde6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas_ta as pta\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "#import talib as ta\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, LeakyReLU, LSTM\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-df5634a5-2baa-457b-b670-efd2ed7963fe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 424,
    "execution_start": 1636847863835,
    "source_hash": "917f2514",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read SpyData CSV\n",
    "spyData = pd.read_csv('Data/XOM.csv', sep = \",\")\n",
    "\n",
    "#Compute RSI\n",
    "\"\"\"\n",
    "rsi = pta.rsi(np.array(spyData.Close), length = 14)\n",
    "\"\"\"\n",
    "\n",
    "#Compute EMA**\n",
    "\n",
    "#Compute STOCH %K & %D\n",
    "\n",
    "stochKD = pta.stoch(low = spyData.Low, high = spyData.High, close = spyData.Close, k=14, d=3, smooth_k = 9)\n",
    "stochKD = stochKD.iloc[10: , :]\n",
    "spyData = spyData.iloc[23: , :]\n",
    "\n",
    "spyData.reset_index(inplace = True)\n",
    "spyData = spyData.drop(\"index\", 1)\n",
    "\n",
    "spyData[\"%K\"] = np.array(stochKD.STOCHk_14_3_9)\n",
    "spyData[\"%D\"] = np.array(stochKD.STOCHd_14_3_9)\n",
    "\n",
    "#Adding the slope the stoch lines (1 pos, 0 neg)\n",
    "\"\"\"\"\n",
    "stochSlope = []\n",
    "for i in range(spyData.shape[0]):\n",
    "    if(spyData[\"%K\"][i] > spyData[\"%D\"][i]):\n",
    "        stochSlope.append(1)\n",
    "    if(spyData[\"%K\"][i] < spyData[\"%D\"][i]):\n",
    "        stochSlope.append(0)\n",
    "\n",
    "spyData[\"Stoch Slope\"] = np.array(stochSlope)\n",
    "\"\"\"\n",
    "\n",
    "#Compute Price 1 | 0 price in 10d (1 = up & 0 = down)\n",
    "\n",
    "tenDay = []\n",
    "for i in range(spyData.shape[0]-10):\n",
    "    if(spyData.Close[i] - spyData.Close[i+10] < 0):\n",
    "        tenDay.append(1)\n",
    "    else:\n",
    "        tenDay.append(0)\n",
    "spyData = spyData.iloc[:-10]\n",
    "spyData[\"Ten Day Gain\"] = np.array(tenDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-621629e7-0293-4a5f-9763-cee685cd4e74",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1636847864269,
    "source_hash": "325d4463",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove Columns\n",
    "\n",
    "spyData = spyData.drop([\"Adj Close\", \"Volume\",\"Date\", \"%K\", \"%D\"], 1)\n",
    "#spyData = spyData.drop(\"Stoch Slope\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-0067e481-758d-4d94-9ccb-32e2f8ccfe86",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 771,
    "execution_start": 1636847864291,
    "source_hash": "f64db71d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = spyData.shape[0]\n",
    "splitRow = int(n * 0.80)\n",
    "spyData2 = spyData.to_numpy()\n",
    "\n",
    "#Splits\n",
    "x_train = spyData2[:splitRow, :-1]\n",
    "y_train = spyData2[:splitRow, -1]\n",
    "x_test = spyData2[splitRow:, :-1]\n",
    "y_test = spyData2[splitRow:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-17bb81a5-c404-4a37-b89a-1c6d17bda6a4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1636847865071,
    "source_hash": "4122185c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#norm = MinMaxScaler()\n",
    "#x_train = norm.fit_transform(x_train)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, activation=\"relu\"))\n",
    "model.add(Dense(12, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"softmax\")) #SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 11.7906 - accuracy: 0.5412\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 7.8282 - accuracy: 0.5412\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4.6062 - accuracy: 0.5412\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8690 - accuracy: 0.5412\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7926 - accuracy: 0.5412\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3360 - accuracy: 0.5412\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3369 - accuracy: 0.5412\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9179 - accuracy: 0.5412\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.5412\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8495 - accuracy: 0.5412\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8018 - accuracy: 0.5412\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.5412\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7226 - accuracy: 0.5412\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.5412\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5412\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.5412\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.5412\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5412\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5412\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5412\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5412\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5412\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5412\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5412\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5412\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5412\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5412\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5412\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5412\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5412\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5412\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5412\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5412\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5412\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5412\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5412\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5412\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5412\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6906 - accuracy: 0.5412\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5412\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5412\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5412\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5412\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.5412\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5412\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5412\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5412\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.5412\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5412\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5412\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5412\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5412\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5412\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5412\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5412\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5412\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5412\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5412\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5412\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5412\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5412\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5412\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5412\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5412\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5412\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5412\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5412\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5412\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5412\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5412\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5412\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5412\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5412\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5412\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5412\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5412\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5412\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5412\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5412\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5412\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5412\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5412\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5412\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5412\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5412\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5412\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.5412\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5412\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5412\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5412\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5412\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5412\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5412\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5412\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5412\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5412\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5412\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5412\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5412\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5412\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5412\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5412\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5412\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5412\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5412\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5412\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5412\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5412\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5412\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5412\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5412\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5412\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5412\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.5412\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5412\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5412\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5412\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5412\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5412\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5412\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5412\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5412\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5412\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5412\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d5c8def940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=150, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-1d1b35eb-533a-4ddb-b497-f2547e5889aa",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### TESLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-12b6e59d-cd73-4a20-a6cd-ca3700b4e0fc",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-dcf2e576-606b-4911-889e-1fd0e9a48b23",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1636852179386,
    "source_hash": "8ad363a6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read In Data\n",
    "tsla = pd.read_csv('Data/TSLA.csv', sep = \",\")\n",
    "tsla.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-6ed4d8a3-ef1c-4113-b098-b91418d22732",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-0600dd01-ad3c-409f-b149-cb1fbb3b98fe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 55,
    "execution_start": 1636844261908,
    "source_hash": "6fe5663",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsla1 = tsla.dropna()\n",
    "tsla1['Open10'] = tsla1['Open'].shift(periods = -14)\n",
    "tsla1 = tsla1.dropna()\n",
    "tsla1['label'] = np.where(tsla1['Open'] < tsla1['Open10'], 1, 0)\n",
    "tsla1a = tsla1.drop(labels = ['Date', 'Adj Close', 'Open10'], axis = 1)\n",
    "tsla1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-28afce52-76b3-4d6c-80ca-e192697c9379",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 351,
    "execution_start": 1636844265700,
    "source_hash": "b11b88bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, _ = tsla1a.shape\n",
    "splitRow = int(x * 0.80)\n",
    "tsla1b = tsla1a.to_numpy()\n",
    "\n",
    "# Training data and testing data\n",
    "trainX = tsla1b[:splitRow, :-1]\n",
    "trainY = tsla1b[:splitRow, -1]\n",
    "testX = tsla1b[splitRow:, :-1]\n",
    "testY = tsla1b[splitRow:, -1] \n",
    "\n",
    "xPlot = range(0, x)\n",
    "plt.figure()\n",
    "plt.title('Data Separation')\n",
    "plt.grid(True)\n",
    "plt.ylabel('Open Price')\n",
    "plt.plot(xPlot[:splitRow], trainX[:,0], 'blue', label='Train data')\n",
    "plt.plot(xPlot[splitRow:], testX[:,0], 'red', label='Test data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-8e26aff8-2751-4d36-9c2a-d4e26de0e232",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1636844268897,
    "source_hash": "31fdc661",
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm = MinMaxScaler()\n",
    "trainX = norm.fit_transform(trainX)\n",
    "\n",
    "trainX = trainX.reshape(trainX.shape[0], trainX.shape[1], 1)\n",
    "testX = testX.reshape(testX.shape[0], testX.shape[1], 1)\n",
    "\n",
    "nFeatures = trainX.shape[1]\n",
    "epochs = 20\n",
    "batchSize = 1000\n",
    "nOutput = 1\n",
    "kernelSize = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-219d8dca-1cce-4492-8ee6-c90636884d0d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4487,
    "execution_start": 1636844272853,
    "source_hash": "e6208a8d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 32, kernel_size = kernelSize, padding = 'same', activation = 'relu', input_shape = (nFeatures, 1)))\n",
    "model.add(Conv1D(filters = 64, kernel_size = kernelSize, padding = 'same'))\n",
    "model.add(LeakyReLU(alpha = 0.01))\n",
    "model.add(MaxPooling1D(pool_size = (1)))\n",
    "model.add(Conv1D(filters = 128, kernel_size = kernelSize, padding = 'same'))\n",
    "model.add(LeakyReLU(alpha = 0.01))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(nOutput, activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "fitReturn = model.fit(trainX, trainY, validation_data=(testX, testY), epochs = epochs, batch_size = batchSize, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-bd6258d0-b0bd-47df-b20a-d310c4acbaa5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 336,
    "execution_start": 1636844283761,
    "source_hash": "da94b64a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.plot(fitReturn.history['loss'], 'blue', label='Train Loss')\n",
    "plt.plot(fitReturn.history['val_loss'], 'red', label='Test Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-1d26fbf9-1e65-4ed5-b2d3-c96b371b6971",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 248,
    "execution_start": 1636844288403,
    "source_hash": "75abef69",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.plot(fitReturn.history['accuracy'], 'blue', label='Train Accuracy')\n",
    "plt.plot(fitReturn.history['val_accuracy'], 'red', label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-932911aa-8fbc-414b-85ca-7cf63fb4d0ee",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 152,
    "execution_start": 1636844294546,
    "source_hash": "187cdca6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictY = model.predict(testX)\n",
    "predictY = predictY[:, 0]\n",
    "\n",
    "# Basic Counting\n",
    "testY0 = (testY == 0).sum()\n",
    "testY1 = (testY == 1).sum()\n",
    "print(\"Test Set - Sell signal : \"+str(testY0))\n",
    "print(\"Test Set - Buy signal  : \"+str(testY1))\n",
    "print(\"=\"*40)\n",
    "predictY0 = (predictY == 0).sum()\n",
    "predictY1 = (predictY == 1).sum()\n",
    "print(\"Predicted - Sell signal : \"+str(predictY0))\n",
    "print(\"Predicted - Buy signal  : \"+str(predictY1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-286dc761-1f21-47ec-b5f4-af019625d868",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 251,
    "execution_start": 1636844735386,
    "source_hash": "23d2ec43",
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(testY, predictY)\n",
    "precision = precision_score(testY, predictY)\n",
    "print('Accuracy: '+str(accuracy))\n",
    "print('Precision: '+str(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-bcbec868-8a20-4c7b-bb1c-2e3feb16bdc0",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-d4c8bc47-7dc1-4e28-b2b0-d47d277240d0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 75,
    "execution_start": 1636829354114,
    "source_hash": "41340919",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsla2 = tsla.dropna()\n",
    "tsla2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-ac6ebd16-d63e-4ae5-ade5-64cbdf3fb955",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 115,
    "execution_start": 1636756283662,
    "source_hash": "ad0c460c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsla2['S_10'] = tsla2['Close'].rolling(window = 14).mean()\n",
    "tsla2['Corr'] = tsla2['Close'].rolling(window = 14).corr(tsla2['S_10'])\n",
    "#tsla2['RSI'] = ta.RSI(np.array(tsla2['Close']), timeperiod = 14)\n",
    "# The difference between the open price of yesterday and today\n",
    "tsla2['Open-Close'] = tsla2['Open'] - tsla2['Close'].shift(1)\n",
    "# The difference close price of yesterday and the open price of today\n",
    "tsla2['Open-Open'] = tsla2['Open'] - tsla2['Open'].shift(1)\n",
    "tsla2 = tsla2.dropna()\n",
    "tsla2 = tsla2.drop(['Date', 'Adj Close', 'Volume'], axis = 1)\n",
    "X = tsla2.iloc[:,:9]\n",
    "tsla2\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-9dab7005-94f4-4572-8656-c1c5aba2f639",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1636756286850,
    "source_hash": "8920b792",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.where(tsla2['Close'].shift(-1) > tsla2['Close'],1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-a03da9ac-5e52-4aba-8133-dd09879fdcb9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1636756291888,
    "source_hash": "e77aa529",
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = int(0.7 * len(tsla2))\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-49fffcff-b93a-4987-b9ac-a268e57dda9d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 189,
    "execution_start": 1636756295867,
    "source_hash": "2eaeef42",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model = model.fit (X_train, y_train)\n",
    "pd.DataFrame(zip(X.columns, np.transpose(model.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-77e868a9-0629-4122-9d75-a954dff43669",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1636756299635,
    "source_hash": "fb897462",
    "tags": []
   },
   "outputs": [],
   "source": [
    "probability = model.predict_proba(X_test)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00019-88e7420e-6b55-4430-8beb-16555782b23d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1636756301451,
    "source_hash": "f6faeb2e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "probability = model.predict_proba(X_test)\n",
    "print(probability)\n",
    "\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00020-2f6aa4b3-9320-408f-9c70-6e10a4925f4c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 20,
    "execution_start": 1636756303141,
    "source_hash": "b65bf41f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00021-c96f9754-908b-4a79-a882-fa0f3d50d341",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1044,
    "execution_start": 1636756305166,
    "source_hash": "483a455f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_val = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "print(cross_val)\n",
    "print(cross_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-50d91828-508c-4fef-af6a-befc04215a29",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### k-Nearest Neigbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00033-362b3ce2-5056-4184-9571-ea9d24479fdd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 68,
    "execution_start": 1636756309241,
    "source_hash": "81f7fc38",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsla3 = tsla.dropna()\n",
    "tsla3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00034-60fb8c87-3b84-4510-8bd2-eb3fd775c91f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1636756311497,
    "source_hash": "9ce5d7d6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsla3 = tsla3[['Open', 'High', 'Close', 'Low']]\n",
    "tsla3['Open-Close'] = tsla3.Open - tsla3.Close\n",
    "tsla3['High-Low'] = tsla3.High = tsla3.Low\n",
    "tsla3 = tsla3.dropna()\n",
    "X_knn = tsla3[['Open-Close', 'High-Low']]\n",
    "Y_knn = np.where(tsla3['Close'].shift(-1) > tsla3['Close'], 1, -1)\n",
    "split3 = int(0.7 * len(tsla3))\n",
    "\n",
    "X_train_knn = tsla3[:split3]\n",
    "Y_train_knn = Y_knn[:split3]\n",
    "X_test_knn = tsla3[split3:]\n",
    "Y_test_knn = Y_knn[split3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00034-ed3a2a75-03a3-4e16-8f8e-2d5fd93fa8e6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15967,
    "execution_start": 1636756314296,
    "source_hash": "153f69da",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "\n",
    "for i in range(1, 151, 5):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i * 10)\n",
    "    knn.fit(X_train_knn, Y_train_knn)\n",
    "    train.append(accuracy_score(Y_train_knn, knn.predict(X_train_knn)))\n",
    "    test.append(accuracy_score(Y_test_knn, knn.predict(X_test_knn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00036-590303c4-6084-46ee-bc46-4aaaeccfe56a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 291,
    "execution_start": 1636756341477,
    "source_hash": "d47cd524",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(train)\n",
    "plt.plot(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00037-1e3f1ae6-0537-4e86-b531-9f68569bd063",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1636756345535,
    "source_hash": "dbde019c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Average of the training set =\", round(sum(train)/len(train), 2))\n",
    "print(\"Average of the testing set =\", round(sum(test)/len(test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00043-5c94cd62-3871-4f69-9a67-4c65be69fbcc",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00046-168c4b6b-5fba-46c9-bb48-f246d31e9617",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 342,
    "execution_start": 1636852197528,
    "source_hash": "a80cf57e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.title('Close Price History')\n",
    "plt.plot(tsla['Close'])\n",
    "plt.xlabel('Data', fontsize=15 )\n",
    "plt.ylabel('Close Price USD ($)', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00047-2e5af09b-a676-414b-87bd-916d79657916",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1636852200182,
    "source_hash": "b9025e39",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a dataframe with only the 'Create Column\n",
    "data = tsla.filter(['Close'])\n",
    "print(data)\n",
    "#convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "#get the number of rows to train the model on\n",
    "training_data_len= math.ceil(len(dataset)* 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00047-83cbeb26-78f9-4ebb-afc8-97e048c8809c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1636852207488,
    "source_hash": "b8416c8c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Scale the all of the data to be values between 0 and 1 \n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00048-7ddca1cc-9c7e-4a07-bad6-8370d69705dd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1636852210930,
    "source_hash": "db3e25fb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create the scaled training data set \n",
    "train_data = scaled_data[0:training_data_len  , : ]\n",
    "#Split the data into x_train and y_train data sets\n",
    "x_train=[]\n",
    "y_train = []\n",
    "for i in range(180,len(train_data)):\n",
    "    x_train.append(train_data[i-180:i,0])\n",
    "    y_train.append(train_data[i,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00049-7d72b903-999a-40f0-924e-5c22bbf47ee4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1636852223358,
    "source_hash": "b3f24923",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "#Reshape the data into the shape accepted by the LSTM\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00050-0f243b09-09b2-491b-95e7-7f6ebb3e2508",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 810,
    "execution_start": 1636852225838,
    "source_hash": "e6547dde",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True,input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dense(units=25))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00051-4232a14f-36fd-4744-88b9-7bab7229544d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 220177,
    "execution_start": 1636852232015,
    "source_hash": "6ff8be3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00052-8d153e66-cc4a-4b62-880b-e1da629832bf",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1636852452191,
    "source_hash": "4a642b83",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test data set\n",
    "test_data = scaled_data[training_data_len - 180: , : ]\n",
    "#Create the x_test and y_test data sets\n",
    "x_test = []\n",
    "y_test =  dataset[training_data_len : , : ] \n",
    "for i in range(180,len(test_data)):\n",
    "    x_test.append(test_data[i-180:i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00053-fd733222-3ed4-437c-a375-96c9f823e1d8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1728,
    "execution_start": 1636852452191,
    "source_hash": "2540208c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "#Getting the models predicted price values\n",
    "predictions = model.predict(x_test) \n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "#Undo scaling\n",
    "rmse = math.sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(rmse)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00054-2810e3f8-d2d5-40fb-9474-ff57c1221213",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 346,
    "execution_start": 1636852453921,
    "source_hash": "3e744801",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "plt.plot(y_test,color='red',label='Real Tesla Stock price')\n",
    "plt.plot(predictions,color='blue',label='Predicted Tesla Stock price')\n",
    "plt.title('Tesla stock price prediction using LSTM')\n",
    "plt.xlabel('Timeline (13th July- 14th August 2020)')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnoteSessionId": "dea8a0f5-35e3-4468-94eb-804ff5fc7baa",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "0f460af1-1872-4aa4-804e-36716dbf15fd",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
